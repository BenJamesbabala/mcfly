{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAMAP2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import urllib.request\n",
    "#url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00231/PAMAP2_Dataset.zip'\n",
    "#local_fn, headers = urllib.request.urlretrieve(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376417, 54)\n",
      "['timestamp', 'activityID', 'heartrate', 'hand_temperature', 'hand_acc_16g_x', 'hand_acc_16g_y', 'hand_acc_16g_z', 'hand_acc_6g_x', 'hand_acc_6g_y', 'hand_acc_6g_z', 'hand_gyroscope_x', 'hand_gyroscope_y', 'hand_gyroscope_z', 'hand_magnometer_x', 'hand_magnometer_y', 'hand_magnometer_z', 'hand_orientation_0', 'hand_orientation_1', 'hand_orientation_2', 'hand_orientation_3', 'chest_temperature', 'chest_acc_16g_x', 'chest_acc_16g_y', 'chest_acc_16g_z', 'chest_acc_6g_x', 'chest_acc_6g_y', 'chest_acc_6g_z', 'chest_gyroscope_x', 'chest_gyroscope_y', 'chest_gyroscope_z', 'chest_magnometer_x', 'chest_magnometer_y', 'chest_magnometer_z', 'chest_orientation_0', 'chest_orientation_1', 'chest_orientation_2', 'chest_orientation_3', 'ankle_temperature', 'ankle_acc_16g_x', 'ankle_acc_16g_y', 'ankle_acc_16g_z', 'ankle_acc_6g_x', 'ankle_acc_6g_y', 'ankle_acc_6g_z', 'ankle_gyroscope_x', 'ankle_gyroscope_y', 'ankle_gyroscope_z', 'ankle_magnometer_x', 'ankle_magnometer_y', 'ankle_magnometer_z', 'ankle_orientation_0', 'ankle_orientation_1', 'ankle_orientation_2', 'ankle_orientation_3']\n"
     ]
    }
   ],
   "source": [
    "datadir = \"/media/sf_VBox_Shared/timeseries/PAMAP2_Dataset/Protocol\"\n",
    "filenames = listdir(datadir)\n",
    "\n",
    "axes = ['x', 'y', 'z']\n",
    "IMUsensor_columns = ['temperature'] + \\\n",
    "                    ['acc_16g_' + i for i in axes] + \\\n",
    "                    ['acc_6g_' + i for i in axes] + \\\n",
    "                    ['gyroscope_'+ i for i in axes] + \\\n",
    "                    ['magnometer_'+ i for i in axes] + \\\n",
    "                    ['orientation_' + str(i) for i in range(4)]\n",
    "header = [\"timestamp\", \"activityID\", \"heartrate\"] + [\"hand_\"+s for s in IMUsensor_columns]\\\n",
    "        + [\"chest_\"+s for s in IMUsensor_columns]+ [\"ankle_\"+s for s in IMUsensor_columns]\n",
    "datasets = [pd.read_csv(datadir+'/'+fn, header=None, sep=' ') for fn in filenames]\n",
    "for data in datasets:\n",
    "    data.columns = header\n",
    "\n",
    "data = datasets[0]    \n",
    "print(data.shape)\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we need to exclude activity=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fill data\n",
    "datasets_filled = [d.interpolate() for d in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select columns\n",
    "columns_to_use = ['hand_acc_16g_x', 'hand_acc_16g_y', 'hand_acc_16g_z',\n",
    "                 'ankle_acc_16g_x', 'ankle_acc_16g_y', 'ankle_acc_16g_z',\n",
    "                 'chest_acc_16g_x', 'chest_acc_16g_y', 'chest_acc_16g_z']\n",
    "columns = data.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create mapping for class labels\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_set_all = [set(np.array(data.activityID)) - set([0]) for data in datasets_filled]\n",
    "classlabels = list(set.union(*[set(y) for y in y_set_all]))\n",
    "nr_classes = len(classlabels)\n",
    "mapclasses = {classlabels[i] : i for i in range(len(classlabels))}\n",
    "def transform_y(y):\n",
    "    y_mapped = np.array([mapclasses[c] for c in y], dtype='int')\n",
    "    y_binary = to_categorical(y_mapped, nr_classes)\n",
    "    return y_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolate activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def split_activities(labels, X, borders=10*100):\n",
    "    \"\"\"\n",
    "    Splits up the data per activity and exclude activity=0.\n",
    "    Also remove borders for each activity.\n",
    "    Returns lists with subdatasets\n",
    "    \"\"\"\n",
    "    tot_len = len(labels)\n",
    "    startpoints = np.where([1] + [labels[i]!=labels[i-1] for i in range(1, tot_len)])[0]\n",
    "    endpoints = np.append(startpoints[1:]-1, tot_len-1)\n",
    "    acts = [labels[s] for s,e in zip(startpoints, endpoints)]\n",
    "    #Also split up the data, and only keep the non-zero activities\n",
    "    Xy_split = [(X[s+borders:e-borders+1,:], a) for s,e,a in zip(startpoints, endpoints, acts) if a != 0]\n",
    "    Xy_split = [(X, y) for X,y in Xy_split if len(X)>0]\n",
    "    X_list = [X for X,y in Xy_split]\n",
    "    y_list = [y for X,y in Xy_split]\n",
    "    return X_list, y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 14 14\n"
     ]
    }
   ],
   "source": [
    "#Create input (X) and output (y) sets\n",
    "X_all = [np.array(data[columns_to_use]) for data in datasets_filled]\n",
    "y_all = [np.array(data.activityID) for data in datasets_filled]\n",
    "Xy_lists = [split_activities(y, X) for X,y in zip(X_all, y_all)]\n",
    "X_lists, y_lists = zip(*Xy_lists)\n",
    "y_binary_lists = [transform_y(y) for y in y_lists]\n",
    "print(len(X_lists[0]), len(y_lists[0]), len(y_binary_lists[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376417, 9)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25187, 21480, 19717, 21573, 20941, 6120, 5480, 5770, 5419, 20253, 18265, 21575, 19265, 10912]\n",
      "[21430, 20345, 23576, 26880, 18683, 6725, 5791, 6617, 5422, 30533, 27739, 23108, 7238, 11262]\n",
      "[20044, 26761, 18533, 25975, 18325, 3764, 3435, 2867, 2954, 2644, 27036]\n",
      "[21047, 23492, 22706, 22995, 18037, 6535, 5328, 6159, 4957, 29932, 25533, 20699]\n",
      "[21699, 24864, 20132, 31034, 22445, 4110, 4982, 6171, 3745, 30033, 24271, 22577, 22646, 5733]\n",
      "[21340, 21041, 22356, 35744, 19078, 4232, 4173, 5059, 3099, 23721, 24686, 18486, 20825]\n",
      "[23611, 10282, 23751, 27499, 19552, 7102, 4290, 6544, 3328, 31720, 26725, 20680, 1692]\n",
      "[22165, 20923, 23160, 30990, 22292, 3901, 2846, 3782, 2809, 29533, 23475, 26888, 14532, 6806]\n",
      "[4391]\n"
     ]
    }
   ],
   "source": [
    "for X in X_lists:\n",
    "    print([Xs.shape[0] for Xs in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split in train, test and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(datasets_filled))\n",
    "train_range = slice(0, 6)\n",
    "val_range = 6\n",
    "test_range = slice(7,len(datasets_filled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_list = [X for X_list in X_lists[train_range] for X in X_list]\n",
    "X_val_list = [X for X in X_lists[val_range]]\n",
    "X_test_list = [X for X_list in X_lists[test_range] for X in X_list]\n",
    "\n",
    "y_train_list = [y for y_list in y_binary_lists[train_range] for y in y_list]\n",
    "y_val_list = [y for y in y_binary_lists[val_range]]\n",
    "y_test_list = [y for y_list in y_binary_lists[test_range] for y in y_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 (25187, 9)\n",
      "78 (12,)\n",
      "13 (23611, 9)\n",
      "13 (12,)\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_list), X_train_list[0].shape)\n",
    "print(len(y_train_list), y_train_list[0].shape)\n",
    "print(len(X_val_list), X_val_list[0].shape)\n",
    "print(len(y_val_list), y_val_list[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take sliding-window frames. Target is label of last time step\n",
    "# Data is 100 Hz\n",
    "frame_length = int(5.12 * 100)\n",
    "step = 1 * 100\n",
    "\n",
    "def sliding_window(X, y_binary, frame_length, step, X_samples, y_samples):\n",
    "    for i in range(0, X.shape[0]-frame_length, step):\n",
    "        X_sub = X[i:i+frame_length,:]\n",
    "        y_sub = y_binary\n",
    "        X_samples.append(X_sub)\n",
    "        y_samples.append(y_sub)\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_val = []\n",
    "y_val = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "for j in range(len(X_train_list)):\n",
    "    X = X_train_list[j]\n",
    "    y_binary = y_train_list[j]\n",
    "    sliding_window(X, y_binary, frame_length, step, X_train, y_train)\n",
    "for j in range(len(X_val_list)):\n",
    "    X = X_val_list[j]\n",
    "    y_binary = y_val_list[j]\n",
    "    sliding_window(X, y_binary, frame_length, step, X_val, y_val)\n",
    "for j in range(len(X_test_list)):\n",
    "    X = X_test_list[j]\n",
    "    y_binary = y_test_list[j]\n",
    "    sliding_window(X, y_binary, frame_length, step, X_test, y_test)\n",
    "    \n",
    "        \n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "#Shuffle around the train set\n",
    "np.random.seed(123)\n",
    "neworder = np.random.permutation(X_train.shape[0])\n",
    "X_train = X_train[neworder,:,:]\n",
    "y_train = y_train[neworder,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12497, 512, 9) (12497, 12)\n",
      "(2007, 512, 9) (2007, 12)\n",
      "(2314, 512, 9) (2314, 12)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "#Test and validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save binary file\n",
    "outdatapath = '/media/sf_VBox_Shared/timeseries/PAMAP2_Dataset/slidingwindow512cleaned/'\n",
    "np.save(outdatapath+'X_train', X_train)\n",
    "np.save(outdatapath+'y_train_binary', y_train)\n",
    "np.save(outdatapath+'X_val', X_val)\n",
    "np.save(outdatapath+'y_val_binary', y_val)\n",
    "np.save(outdatapath+'X_test', X_test)\n",
    "np.save(outdatapath+'y_test_binary', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(X_train == np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156.19"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155.96\n",
      "155.996\n",
      "156.19\n",
      "86.7261\n",
      "156.73\n",
      "156.949\n",
      "157.232\n",
      "158.872\n",
      "160.516\n"
     ]
    }
   ],
   "source": [
    "for X in X_all:\n",
    "    print(X.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.interpolate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
