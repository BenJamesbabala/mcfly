{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Objective:\n",
    "# User-friendly function to load time series data and labels and feed it into the training/application\n",
    "# In this notebook I am preparing the code snippets to make up such a function, and also to identify the\n",
    "# possible needs for standardisation in input format\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Short clarification on terminalogy\n",
    "# The term measurement refers to one entity of investigation, e.g. in a patient/animal/,\n",
    "# within which  we want to classify something, e.g. behaviour, disease, ...\n",
    "# The term dataset refers to a set of entities between one may want to study differences in classification\n",
    "#============================================================================\n",
    "# Input:\n",
    "\n",
    "studyname = 'Utrecht' # to simplify switching between datasets when testing\n",
    "# Minimum amount of user input need to interpret data:\n",
    "if studyname == 'Utrecht':\n",
    "    datadir = \"/home/vincent/estep/data/utrecht\"\n",
    "    multivar = True #False # Are this Multivariate time series TRUE or FALSE\n",
    "    multiclass = False\n",
    "    Nfilesperelement = 4 #there are four files per patient\n",
    "    labloc = \"/home/vincent/estep/data/utrecht_labels.csv\" # labels in column 1 (0), row 1 (1), or name of file\n",
    "    idbloc = 2 # Id in column 1 (0), row 1 (1), seperate file (2), not applicable (3)\n",
    "    labint = True # Is the label an integer?\n",
    "    timecol = False # time series per column (True) or per row (False)\n",
    "elif studyname == 'UCR':\n",
    "    datadir = \"/home/vincent/estep/data/UCR_TS_Archive_2015/50words\"\n",
    "    multivar = False # Are this Multivariate time series TRUE or FALSE\n",
    "    multiclass = False\n",
    "    Nfilesperelement = 0 #all elements are in one merged file\n",
    "    labloc = 0 # Classifcation labels in column 1 (0), row 1 (1), seperate file (2)\n",
    "    idbloc = 3 # Id in column 1 (0), row 1 (1), seperate file (2), not applicable (3)\n",
    "    labint = True # Is the label an integer?\n",
    "    timecol = False # time series per column (True) or per row (False)\n",
    "elif studyname == 'London':\n",
    "    datadir = \"/home/vincent/estep/data/london/accelerometer_40Hz\"\n",
    "    multivar = True # Are this Multivariate time series TRUE or FALSE\n",
    "    multiclass = True\n",
    "    Nfilesperelement = 1 #one file per person\n",
    "    labloc = \"/home/vincent/estep/data/london_labels.csv\" # Classifcation labels in column 1 (0), row 1 (1), seperate file (2)\n",
    "    idbloc = 2 # Id in column 1 (0), row 1 (1), seperate file (2), not applicable (3)\n",
    "    labint = False # Is the label an integer?\n",
    "    timecol = True # time series per column (True) or per row (False)\n",
    "#============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Identify number of files and filetype based on datadir\n",
    "filenames = listdir(datadir)\n",
    "Nfiles = len(filenames) # number of files\n",
    "TXTFILES = [m.endswith('.txt') for m in filenames] # check which files are textfiles\n",
    "CSVFILES = [m.endswith('.csv') for m in filenames] # check which files are csvfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  delimiter skiprows  nrow ncol first cell\n",
      "0      None        0  4667   21   -0.78125\n",
      "1      None        1  4666   21    -5.7617\n",
      "2         ,        0     0    0          0\n",
      "3         ,        1     0    0          0\n"
     ]
    }
   ],
   "source": [
    "# Investigate what format the first file has by trying out a variety of reading attempts\n",
    "path = datadir + '/' + filenames[1]\n",
    "delimiter = [None,','] #possible delimiter values\n",
    "skiprows=[0,1]\n",
    "ntests = len(delimiter)*len(skiprows)\n",
    "df = pd.DataFrame(index=range(ntests),columns=['delimiter','skiprows','nrow','ncol','first cell'])\n",
    "cnt = 0\n",
    "for di in delimiter:\n",
    "    for si in skiprows:\n",
    "        try:\n",
    "            F1 = np.loadtxt(fname=path,delimiter=di,skiprows=si)\n",
    "            df['delimiter'][cnt] = di\n",
    "            df['skiprows'][cnt] = si\n",
    "            df['nrow'][cnt] = F1.shape[0]\n",
    "            df['ncol'][cnt] = F1.shape[1]\n",
    "            df['first cell'][cnt] = F1[0,1]\n",
    "        except:\n",
    "            df['delimiter'][cnt] = di\n",
    "            df['skiprows'][cnt] = si\n",
    "            df['nrow'][cnt] = 0\n",
    "            df['ncol'][cnt] = 0\n",
    "            df['first cell'][cnt] = 0\n",
    "        cnt = cnt + 1\n",
    "# df is now a dataframe with information to help identify how the data should be loaded        \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load one file based on the extracted information on fileformat\n",
    "form = df[df.nrow == max(df.nrow)] # extraction procedure that resulted in the largest number of rows is the best\n",
    "if form.shape[0] > 1:\n",
    "    form = df[df.ncol == max(df.ncol)] # extraction procedure that resulted in the largest number of columns\n",
    "\n",
    "if (form['delimiter'] == ',').bool():\n",
    "    F2 = np.loadtxt(fname=path,delimiter=',',skiprows=int(form['skiprows']))\n",
    "else:\n",
    "    F2 = np.loadtxt(fname=path,delimiter=None,skiprows=int(form['skiprows']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.9297 , -0.78125, -2.9297 ],\n",
       "       [ 3.7109 , -5.7617 , -4.6875 ],\n",
       "       [-0.39062, -8.3008 , -5.6641 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F2[0:3,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract labels y and data X, and standardize shape of matrix\n",
    "# Extract data based on newly gained insight into fileformat and data structure\n",
    "if labint == True:\n",
    "    labtype = 'int'\n",
    "else:\n",
    "    labtype = 'str'\n",
    "if type(labloc) == str:\n",
    "    #y = genfromtxt(labloc, delimiter=',',skip_header=1) # do we want numpy array or pd dataframe?\n",
    "    y = pd.read_csv(labloc, sep=',',header=0)\n",
    "    #y=pd.read_csv(labloc, sep=',',header=None)\n",
    "    # TO DO: y needs to be converted in simple one dimensional array that alligns with X\n",
    "    # - how can we verify which time series links to which label...both should have a unique key\n",
    "    # - in case of utrecht, the key is in the id in the filename, which is also in y\n",
    "    # - is this generic for all seperate file?\n",
    "    # - no, if there is one class per id then we know that it is file level\n",
    "    # - if there are multiple classes per id (e.g. London data) then we know that it is both between and\n",
    "    # within files\n",
    "    if timecol == False:\n",
    "        X = F2.transpose()\n",
    "    else:\n",
    "        X = F2    \n",
    "elif type(labloc) == int:\n",
    "    if labloc == 0:\n",
    "        y = np.array(F2[:,0], dtype=labtype)\n",
    "        X = F2[:,1:]\n",
    "    elif labloc == 1:\n",
    "        y = np.array(F2[0,:], dtype=labtype)\n",
    "        X = F2[1:,:].transpose()   \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((451, 4), (21, 4667))\n"
     ]
    }
   ],
   "source": [
    "print((y.shape, X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if type(labloc) == str and multiclass == True and y.shape[0] != X.shape[0]:\n",
    "    #filter y relevant for this filename, this is relevant for the london labels\n",
    "    y2 = y[y['filename'] == filenames[1].strip('.csv')] #TO DO: make code less specific to London, e.g by\n",
    "    # requiring that identifiers are compatible and that the user can specify the name of the identifier\n",
    "    #now convert this into something with the same shape as X, such that we always have a standardized output\n",
    "    \n",
    "    # convert clock times to samples since start of measurement\n",
    "    #y2['stime'] = y2['stime']\n",
    "    if (y2.shape[0] == X.shape[0]): #no more modification needed, use y2\n",
    "        y = y2\n",
    "    else:\n",
    "        y3 = np.zeros(X.shape[0]) #initialize right shape of y\n",
    "        #for i in range(y2.shape[0]):\n",
    "         # y3[y2['stime'][i]:y2['etime'][i]] = [y2['activity'][i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Exploring how to convert these timestamps into epochs\n",
    "# import time\n",
    "# date_time = str(y2['ddate1'][0]).strip() + \" \" + str(y2['stime'][0]).strip() #'11:05:05'\n",
    "# print(date_time)\n",
    "# pattern = '%d/%m/%Y %H:%M:%S'\n",
    "# epoch = int(time.mktime(time.strptime(date_time, pattern)))\n",
    "# print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are multiple X, one for each data file, and y may either hold one or more labels for each time series\n"
     ]
    }
   ],
   "source": [
    "# the following classification is incorrect, because:\n",
    "# in utrecht data there are not four files per person\n",
    "if y.shape[0] == X.shape[0]: # no more action needed, annotation fits shape of data\n",
    "    print('there is one x with all the time series and an y with corresponding label per time series')\n",
    "elif y.shape[0]*Nfilesperelement == Nfiles: #classification is  per file\n",
    "    print('there are multiple X, one for each data file, and y holds one label for each time series')\n",
    "else:\n",
    "    print('there are multiple X, one for each data file, and y may either hold one or more labels for each time series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1153"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((451, 4), (21, 4667))\n"
     ]
    }
   ],
   "source": [
    "print((y.shape, X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
