{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.3 (default, Oct 14 2015, 20:28:29) \n",
      "[GCC 4.8.4]\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Merge, Dense, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s - loss: 7.9871 - acc: 0.4990     \n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s - loss: 7.9871 - acc: 0.4990     \n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s - loss: 7.9871 - acc: 0.4990     \n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s - loss: 7.9871 - acc: 0.4990     \n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s - loss: 7.9871 - acc: 0.4990     \n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s - loss: 7.9871 - acc: 0.4990     \n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s - loss: 7.9871 - acc: 0.4990     \n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s - loss: 7.9871 - acc: 0.4990     \n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s - loss: 7.9871 - acc: 0.4990     \n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s - loss: 7.9871 - acc: 0.4990     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e5a4d9160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for a single-input model with 2 classes (binary):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=784, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 784))\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "# train the model, iterating on the data in batches\n",
    "# of 32 samples\n",
    "model.fit(data, labels, nb_epoch=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-b57241e1cf3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# this does not work for me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mjson_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "# we can export the weight of the model to Numpy array and then store those anywhere:\n",
    "# myweights = model.get_weigths()\n",
    "\n",
    "# we can also update the weights manually:\n",
    "# model.set_weights(newweighths)\n",
    "\n",
    "# it is possible to export models to json and yaml, but then you need to get the models\n",
    "# this does not work for me\n",
    "\n",
    "from models import model_from_json\n",
    "json_string = model.to_json()\n",
    "model = model_from_json(json_string)\n",
    "\n",
    "from models import model_from_yaml\n",
    "yaml_string = model.to_yaml()\n",
    "model = model_from_yaml(yaml_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Softmax.0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for a multi-input model with 10 classes:\n",
    "\n",
    "left_branch = Sequential()\n",
    "left_branch.add(Dense(32, input_dim=784))\n",
    "\n",
    "right_branch = Sequential()\n",
    "right_branch.add(Dense(32, input_dim=784))\n",
    "\n",
    "merged = Merge([left_branch, right_branch], mode='concat')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(merged)\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# generate dummy data\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "data_1 = np.random.random((1000, 784))\n",
    "data_2 = np.random.random((1000, 784))\n",
    "\n",
    "# these are integers between 0 and 9\n",
    "labels = np.random.randint(10, size=(1000, 1))\n",
    "# we convert the labels to a binary matrix of size (1000, 10)\n",
    "# for use with categorical_crossentropy\n",
    "labels = to_categorical(labels, 10)\n",
    "\n",
    "# train the model\n",
    "# note that we are passing a list of Numpy arrays as training data\n",
    "# since the model has 2 inputs\n",
    "model.fit([data_1, data_2], labels, nb_epoch=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Multilayer Perceptron (MLP) for multi-class softmax classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "# create my own dummy data, because it is not in the example\n",
    "timesteps = 50\n",
    "data_dim = 3\n",
    "nb_classes = 5\n",
    "X_train = np.random.random((100, timesteps))\n",
    "y_train = np.random.randint(nb_classes,size=(100,1))\n",
    "X_test = np.random.random((100, timesteps))\n",
    "y_test = np.random.randint(nb_classes,size=(100,1))\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "idim = timesteps\n",
    "model.add(Dense(64, input_dim=idim, init='uniform'))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, init='uniform'))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes, init='uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 0s - loss: 1.6236 - acc: 0.1700     \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s - loss: 1.6264 - acc: 0.2400     \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s - loss: 1.6284 - acc: 0.1800     \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s - loss: 1.6270 - acc: 0.2300     \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s - loss: 1.6500 - acc: 0.2100     \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s - loss: 1.6035 - acc: 0.2300     \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s - loss: 1.7973 - acc: 0.2000     \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s - loss: 1.8720 - acc: 0.2400     \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s - loss: 2.4324 - acc: 0.2700     \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s - loss: 3.9932 - acc: 0.2100     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f481a5e2dd8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          nb_epoch=10,\n",
    "          batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "\n",
    "score = model.evaluate(X_test, y_test, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0579225778579713, 0.20000000447034835]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Stacked LSTM for sequence classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50 samples, validate on 20 samples\n",
      "Epoch 1/5\n",
      "50/50 [==============================] - 1s - loss: 0.7327 - acc: 0.4000 - val_loss: 0.6877 - val_acc: 0.7000\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 1s - loss: 0.6839 - acc: 0.4800 - val_loss: 0.6830 - val_acc: 0.7000\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 1s - loss: 0.6882 - acc: 0.4800 - val_loss: 0.6877 - val_acc: 0.7000\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 1s - loss: 0.6833 - acc: 0.5400 - val_loss: 0.6931 - val_acc: 0.7000\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 1s - loss: 0.6867 - acc: 0.5400 - val_loss: 0.7076 - val_acc: 0.3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1876942b38>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "data_dim = 3 #three axes\n",
    "timesteps = 200 #4 seconds\n",
    "nb_classes = 2 #two activity types\n",
    "n_train = 50\n",
    "n_val = 20\n",
    "\n",
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32))  # return a single vector of dimension 32\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# generate dummy training data\n",
    "x_train = np.random.random((n_train, timesteps, data_dim))\n",
    "y_train = np.random.random((n_train, nb_classes))\n",
    "\n",
    "# generate dummy validation data\n",
    "x_val = np.random.random((n_val, timesteps, data_dim))\n",
    "y_val = np.random.random((n_val, nb_classes))\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=20, nb_epoch=5,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters are: batch_size, nb_epoch, outputsize for LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Same stacked LSTM model, rendered \"stateful\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /home/vincent/.theano/compiledir_Linux-3.16--generic-x86_64-with-Ubuntu-14.04-trusty-x86_64-3.4.3-64/lock_dir/lock\n",
      "INFO:theano.gof.compilelock:Refreshing lock /home/vincent/.theano/compiledir_Linux-3.16--generic-x86_64-with-Ubuntu-14.04-trusty-x86_64-3.4.3-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples, validate on 45 samples\n",
      "Epoch 1/5\n",
      "150/150 [==============================] - 0s - loss: 4.1485 - acc: 0.1667 - val_loss: 4.1988 - val_acc: 0.1333\n",
      "Epoch 2/5\n",
      "150/150 [==============================] - 0s - loss: 4.1110 - acc: 0.2000 - val_loss: 4.1838 - val_acc: 0.1333\n",
      "Epoch 3/5\n",
      "150/150 [==============================] - 0s - loss: 4.0957 - acc: 0.2667 - val_loss: 4.1838 - val_acc: 0.2444\n",
      "Epoch 4/5\n",
      "150/150 [==============================] - 0s - loss: 4.1015 - acc: 0.2067 - val_loss: 4.1802 - val_acc: 0.1778\n",
      "Epoch 5/5\n",
      "150/150 [==============================] - 0s - loss: 4.0974 - acc: 0.2267 - val_loss: 4.1750 - val_acc: 0.1556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1872cba860>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "data_dim = 3\n",
    "timesteps = 12\n",
    "nb_classes = 5\n",
    "batch_size = 15\n",
    "\n",
    "# expected input batch shape: (batch_size, timesteps, data_dim)\n",
    "# note that we have to provide the full batch_input_shape since the network is stateful.\n",
    "# the sample of index i in batch k is the follow-up for the sample i in batch k-1.\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True, stateful=True,\n",
    "               batch_input_shape=(batch_size, timesteps, data_dim)))\n",
    "model.add(LSTM(32, return_sequences=True, stateful=True))\n",
    "model.add(LSTM(32, stateful=True))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# generate dummy training data\n",
    "x_train = np.random.random((batch_size * 10, timesteps, data_dim))\n",
    "y_train = np.random.random((batch_size * 10, nb_classes))\n",
    "\n",
    "# generate dummy validation data\n",
    "x_val = np.random.random((batch_size * 3, timesteps, data_dim))\n",
    "y_val = np.random.random((batch_size * 3, nb_classes))\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size, nb_epoch=5,\n",
    "          validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
