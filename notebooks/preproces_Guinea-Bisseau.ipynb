{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Guinea-Bissau data and save as numpy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import merge \n",
    "from os import listdir\n",
    "from numpy import genfromtxt, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datadir = \"/media/windows-share/EEGs_Guinea-Bissau_cleaned\"\n",
    "outputdir = \"/media/windows-share/EEGs_Guinea-Bissau_np\"\n",
    "filenames = listdir(datadir)\n",
    "D = []\n",
    "sf = 128\n",
    "nc = 14\n",
    "#Nfiles = len(filenames)\n",
    "#X = np.zeros((Nfiles,maxtslength,nc)) \n",
    "\n",
    "id = list(map(int,list(map(lambda file: file[file.find('id')+2:file.find('dur')-1],filenames))))\n",
    "dur = list(map(int,list(map(lambda file: file[file.find('dur')+3:file.find('epoch')-1],filenames))))\n",
    "epoch = list(map(int,list(map(lambda file: file[file.find('epoch')+5:file.find('gro')-1],filenames))))\n",
    "group = list(map(str,list(map(lambda file: file[file.find('gro')+3:file.find('.csv')],filenames))))\n",
    "protocol = list(map(str,list(map(lambda file: file[file.find('yes')+3:file.find('id')-1],filenames))))\n",
    "mydata = id, dur, epoch, group\n",
    "df = pd.DataFrame.from_items([('id',id),('dur',dur),('epoch',epoch),('group',group),('filenames',filenames),\n",
    "                              ('protocol',protocol)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_4seconds_open 101\n",
      "valid_4seconds_open 20\n",
      "test_4seconds_open 20\n",
      "train_4seconds_closed 137\n",
      "valid_4seconds_closed 20\n",
      "test_4seconds_closed 20\n",
      "train_10seconds_open 78\n",
      "valid_10seconds_open 20\n",
      "test_10seconds_open 20\n",
      "train_10seconds_closed 108\n",
      "valid_10seconds_closed 20\n",
      "test_10seconds_closed 20\n"
     ]
    }
   ],
   "source": [
    "logstructure = []\n",
    "for mindur in [4,10]: # minimum duration of an epoch in minutes\n",
    "    for protocol in ['open','closed']:\n",
    "        df2 = df[(df['protocol']==protocol) & (df['dur'] >= mindur)]\n",
    "        maxtslength = mindur * sf\n",
    "        #Identify training, test and validation group\n",
    "        con = np.unique(df2[df2['group'] == 'Control']['id'])\n",
    "        epi = np.unique(df2[df2['group'] == 'Epilepsy']['id'])\n",
    "        Nid = len(con) + len(epi) #number of ids\n",
    "        prop = len(con) / Nid #proportion of controls\n",
    "        random.seed(300)\n",
    "        def getids(x,y,prop,N):\n",
    "            ix = np.sort(np.random.choice(x,round(N*prop),replace=False))\n",
    "            iy = np.sort(np.random.choice(y,round(N*(1-prop)),replace=False))\n",
    "            if (len(ix)+len(iy)) < 20:\n",
    "                print(prop,N,len(x),len(y))\n",
    "            x = [x for i,x in enumerate(x) if x not in ix]    \n",
    "            y = [x for i,x in enumerate(y) if x not in iy]    \n",
    "            icon = np.concatenate((ix,iy))\n",
    "            return icon, x, y\n",
    "        ival, con, epi = getids(con,epi,prop,N=20) # validation set\n",
    "        ites, con, epi = getids(con,epi,prop,N=20) # test set\n",
    "        itra = np.concatenate((con, epi)) # training set\n",
    "        #print(len(ival),len(ites),len(itra))\n",
    "        # Now use identifies per group to load the data\n",
    "        for subset in ['train','valid','test']:\n",
    "            conditionname = subset+'_'+str(mindur)+'seconds_'+protocol\n",
    "            if subset == 'train':\n",
    "                tmp = df2[df2.id.isin(itra)]\n",
    "                filenames = tmp['filenames']\n",
    "            if subset == 'valid':\n",
    "                tmp = df2[(df2.id.isin(ival))]\n",
    "                tmp = tmp.sort_values(by=['id','epoch']).groupby('id').first() # select first available epoch\n",
    "                filenames = tmp['filenames']\n",
    "            if subset == 'test':\n",
    "                tmp = df2[(df2.id.isin(ival))]\n",
    "                tmp = tmp.sort_values(by=['id','epoch']).groupby('id').first() # select first available epoch\n",
    "                filenames = tmp['filenames']\n",
    "            X = np.zeros((0,maxtslength,nc)) #len(filenames)\n",
    "            print(conditionname + ' ' + str(len(filenames)))\n",
    "            for file in filenames:\n",
    "                path = datadir + '/' + file\n",
    "                D = pd.read_csv(path, sep=',',header=0,usecols=list(range(1,15)))\n",
    "                if D.shape[0] > maxtslength:\n",
    "                    D = np.array(D[0:maxtslength]) # take first part or should these be a random selection?\n",
    "                    D = np.reshape(D,(1,D.shape[0],D.shape[1]))\n",
    "                    X = np.vstack((X,D))\n",
    "                    logstructure.append([subset,mindur,protocol,file])\n",
    "            fnameX = outputdir + '/X_' + conditionname\n",
    "            fnamey = outputdir + '/y_' + conditionname\n",
    "            np.save(file=fnameX,arr=X)\n",
    "            y = np.array(tmp['group'])\n",
    "            np.save(file=fnamey,arr=y)            \n",
    "np.savetxt(outputdir + '/log.csv', logstructure,\n",
    "           delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/windows-share/EEGs_Guinea-Bissau_np/X_test_10seconds_closed\n",
      "/media/windows-share/EEGs_Guinea-Bissau_np/y_test_10seconds_closed\n"
     ]
    }
   ],
   "source": [
    "print(fnameX)\n",
    "print(fnamey)\n",
    "testreadX = np.load(file=fnameX+'.npy')\n",
    "testready = np.load(file=fnamey+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1280, 14)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "print(testreadX.shape)\n",
    "print(testready.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
