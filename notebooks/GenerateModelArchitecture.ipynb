{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load simple dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data from the UCR TS archive, you can get the data at http://www.cs.ucr.edu/~eamonn/time_series_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datapath = '/media/christiaan/extra/timeseries/UCR_TS_Archive_2015'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(896, 316) (3582, 316)\n",
      "(896, 316) (3582, 316)\n",
      "(896, 316) (3582, 316)\n"
     ]
    }
   ],
   "source": [
    "datasets_train = {}\n",
    "datasets_test = {}\n",
    "for i in [\"X\", \"Y\", \"Z\"]:\n",
    "    path_to_data_train = datapath + '/uWaveGestureLibrary_'+i+'/uWaveGestureLibrary_'+i+'_TRAIN'\n",
    "    path_to_data_test = datapath + '/uWaveGestureLibrary_'+i+'/uWaveGestureLibrary_'+i+'_TEST'\n",
    "    datasets_train[i] = np.genfromtxt(path_to_data_train, delimiter=',')\n",
    "    datasets_test[i] = np.genfromtxt(path_to_data_test, delimiter=',')\n",
    "    print(datasets_train[i].shape, datasets_test[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "(896,)\n",
      "(3582,)\n"
     ]
    }
   ],
   "source": [
    "y_train = np.vstack((datasets_train['X'][:,0], datasets_train['Y'][:,0], datasets_train['Z'][:,0])).transpose()\n",
    "#Check labels are the same across channels\n",
    "print(y_train.std(axis=1).sum())\n",
    "y_train = np.array(y_train[:,0], dtype='int')\n",
    "print(y_train.shape)\n",
    "\n",
    "y_test = np.array(datasets_test['X'][:,0], dtype='int')\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(896, 315, 3)\n",
      "(3582, 315, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train  = np.stack((datasets_train['X'][:,1:], datasets_train['Y'][:,1:], datasets_train['Z'][:,1:]), axis=-1)\n",
    "print(X_train.shape)\n",
    "X_test  = np.stack((datasets_test['X'][:,1:], datasets_test['Y'][:,1:], datasets_test['Z'][:,1:]), axis=-1)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.30424, -2.1194 , -1.529  ],\n",
       "        [-0.30424, -2.1194 , -1.529  ],\n",
       "        [-0.30424, -2.1194 , -1.529  ],\n",
       "        [-0.30424, -2.1194 , -1.529  ]],\n",
       "\n",
       "       [[ 1.6273 ,  0.66662,  1.7869 ],\n",
       "        [ 1.6273 ,  0.66662,  1.7869 ],\n",
       "        [ 1.6273 ,  0.66662,  1.7869 ],\n",
       "        [ 1.6273 ,  0.66662,  1.7869 ]],\n",
       "\n",
       "       [[ 0.66128, -0.18973,  0.52125],\n",
       "        [ 0.66128, -0.18973,  0.52125],\n",
       "        [ 0.66128, -0.18973,  0.52125],\n",
       "        [ 0.66128, -0.18973,  0.52125]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:3,:4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Change class labels ranging from 0 to n-1\n",
    "classlabels = list(set(y_train))\n",
    "mapclasses = {classlabels[i] : i for i in range(len(classlabels))}\n",
    "y_train = np.array([mapclasses[c] for c in y_train], dtype='int')\n",
    "y_test = np.array([mapclasses[c] for c in y_test], dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(269, 315, 3)\n"
     ]
    }
   ],
   "source": [
    "ntrain = X_train.shape[0]\n",
    "num_training = int(ntrain * 0.7)\n",
    "num_validation = ntrain - num_training\n",
    "num_test = X_test.shape[0]\n",
    "\n",
    "#First sort the data in random order\n",
    "np.random.seed(123)\n",
    "neworder = np.random.permutation(ntrain)\n",
    "X_train_random = X_train[neworder,:]\n",
    "y_train_random = y_train[neworder]\n",
    "\n",
    "# Our validation set will be num_validation points from the original\n",
    "# training set.\n",
    "mask = range(num_training, num_training + num_validation)\n",
    "X_val = X_train_random[mask]\n",
    "y_val = y_train_random[mask]\n",
    "mask = range(num_training)\n",
    "X_train = X_train_random[mask]\n",
    "y_train = y_train_random[mask]\n",
    "\n",
    "\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# We need to convert the output\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train_binary = to_categorical(y_train)\n",
    "y_val_binary = to_categorical(y_val)\n",
    "y_test_binary = to_categorical(y_test)\n",
    "print(y_train_binary[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution1D, Flatten, MaxPooling1D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_model(x_shape, class_number, filters, fc_hidden, lr = 0.01):\n",
    "    dim_length = x_shape[1]\n",
    "    dim_channels = x_shape[2]\n",
    "    outputdim = class_number\n",
    "    \n",
    "    model = Sequential()\n",
    "    # TODO: weight initialization (in layer constructor)\n",
    "    # TODOL regularation etc\n",
    "    model.add(Convolution1D(filters[0], 3, border_mode='same', input_shape=(dim_length, dim_channels)))\n",
    "    for filter_number in filters[1:]:\n",
    "        model.add(Convolution1D(filter_number, 3, border_mode='same'))\n",
    "        model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(output_dim=fc_hidden)) # Fully connected layer\n",
    "    model.add(Activation('relu')) # Relu activation\n",
    "    model.add(Dense(output_dim=outputdim))\n",
    "    model.add(Activation(\"softmax\")) # Final classification layer    \n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=Adam(lr=lr), \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_models(x_shape, number_of_classes, number_of_models = 5):\n",
    "    models = []\n",
    "    for _ in range(0, number_of_models):\n",
    "        hyperparameters = generate_hyperparameter_set()\n",
    "        filters = hyperparameters['filters']\n",
    "        fc_hidden = hyperparameters['fc_hidden_nodes']\n",
    "        lr = hyperparameters['learning_rate']\n",
    "        models.append(generate_model(x_shape, number_of_classes, filters, fc_hidden, lr))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_hyperparameter_set(min_layers = 1, max_layers = 10, \n",
    "                                 min_filters = 10, max_filters = 100, \n",
    "                                 min_fc_nodes = 10, max_fc_nodes = 100):   \n",
    "    number_of_layers = np.random.randint(min_layers, max_layers)\n",
    "    number_of_filters = np.random.randint(min_filters, max_filters, number_of_layers)\n",
    "    number_of_fc_nodes = np.random.randint(min_fc_nodes, max_fc_nodes)\n",
    "    #TODO generate learning rate, something like: lr = 10**(np.random.nextfloat(1, 4))\n",
    "    return {'filters':number_of_filters, 'fc_hidden_nodes':number_of_fc_nodes, 'learning_rate':lr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model in generate_models(X_train.shape, len(set(y_train))):\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(Convolution1D(32, 3, border_mode='same', input_shape=(dim_length, dim_channels)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_length=2))\n",
    "model.add(Convolution1D(16, 3, border_mode='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(output_dim=30)) # Fully connected layer\n",
    "model.add(Activation('relu')) # Relu activation\n",
    "model.add(Dense(output_dim=outputdim))\n",
    "model.add(Activation(\"softmax\")) # Final classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution1d_13 (Convolution1D)   (None, 315, 32)     320         convolution1d_input_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)          (None, 315, 32)     0           convolution1d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_2 (MaxPooling1D)      (None, 157, 32)     0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_14 (Convolution1D)   (None, 157, 16)     1552        maxpooling1d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)                (None, 2512)        0           convolution1d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                    (None, 30)          75390       flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)          (None, 30)          0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                    (None, 8)           248         activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)          (None, 8)           0           dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 77510\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we configure the learning process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "627/627 [==============================] - 0s - loss: 1.9557 - acc: 0.3014     \n",
      "Epoch 2/10\n",
      "627/627 [==============================] - 1s - loss: 0.8881 - acc: 0.6762     \n",
      "Epoch 3/10\n",
      "627/627 [==============================] - 1s - loss: 0.3561 - acc: 0.8915     \n",
      "Epoch 4/10\n",
      "627/627 [==============================] - 1s - loss: 0.1869 - acc: 0.9346     \n",
      "Epoch 5/10\n",
      "627/627 [==============================] - 1s - loss: 0.1196 - acc: 0.9617     \n",
      "Epoch 6/10\n",
      "627/627 [==============================] - 1s - loss: 0.1190 - acc: 0.9601     \n",
      "Epoch 7/10\n",
      "627/627 [==============================] - 2s - loss: 0.0845 - acc: 0.9777     \n",
      "Epoch 8/10\n",
      "627/627 [==============================] - 1s - loss: 0.0532 - acc: 0.9904     \n",
      "Epoch 9/10\n",
      "627/627 [==============================] - 1s - loss: 0.0369 - acc: 0.9888     \n",
      "Epoch 10/10\n",
      "627/627 [==============================] - 2s - loss: 0.0514 - acc: 0.9856     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f185e6f27f0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_binary, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the model on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40061208661160946, 0.90334572512864175]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_val, y_val_binary, batch_size=32)\n",
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s     \n",
      "269/269 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "classes = model.predict_classes(X_val, batch_size=32)\n",
    "proba = model.predict_proba(X_val, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.87026751e-01   2.74647948e-12   2.53308225e-12 ...,   7.78573437e-08\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.18396146e-14   5.15791311e-15   9.99994814e-01 ...,   2.51816675e-11\n",
      "    2.00000000e+00   2.00000000e+00]\n",
      " [  5.66074592e-14   1.17906616e-15   9.99893546e-01 ...,   1.69729633e-10\n",
      "    2.00000000e+00   2.00000000e+00]\n",
      " ..., \n",
      " [  1.27493013e-06   2.11296810e-06   3.91455070e-13 ...,   1.16394034e-07\n",
      "    5.00000000e+00   5.00000000e+00]\n",
      " [  5.80094941e-02   5.02247632e-10   5.00203760e-06 ...,   2.17904150e-03\n",
      "    5.00000000e+00   5.00000000e+00]\n",
      " [  1.72344642e-13   9.99998152e-01   7.68885045e-09 ...,   5.50384217e-11\n",
      "    1.00000000e+00   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(np.hstack((proba, np.vstack((classes, y_val)).transpose())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute some more metrics, such as the confusion matrix and the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35,  0,  0,  1,  0,  5,  0,  0],\n",
       "       [ 0, 30,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 30,  0,  0,  1,  1,  0],\n",
       "       [ 1,  0,  0, 25,  1,  2,  0,  0],\n",
       "       [ 0,  0,  6,  2, 39,  2,  0,  0],\n",
       "       [ 2,  0,  0,  1,  0, 28,  0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  0, 31,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 25]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(classes, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3582/3582 [==============================] - 2s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32639870815091399, 0.93216080378713984]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, y_test_binary, batch_size=32)\n",
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best score by Dynamic time warping:\n",
    "1 - 0.034 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
