{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import merge \n",
    "from os import listdir\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "studyname = 'Utrecht' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for Utrecht data to create list with filenames that need to be\n",
    "# processed filtered by epoch and diagnosis\n",
    "def select_filenames(datadir,labloc): \n",
    "    # Input:\n",
    "    # - datadir: the path where the files are located\n",
    "    # - labloc: the path and filename of the labels with columns: id, gender, age, diagnosis\n",
    "    # Output:\n",
    "    # - List of filenames for which filename ends with ep1.TRC.txt and diganosis < 3\n",
    "    #======================================================================\n",
    "    filenames = listdir(datadir) \n",
    "    fn = pd.DataFrame(filenames,columns=['filename'])\n",
    "    fn2 = fn.filename.str.split('_',expand=True)\n",
    "    fn2.columns= ['id','epoch']\n",
    "    fn2['filename'] = fn\n",
    "    fn2.id = pd.to_numeric(fn2.id)\n",
    "    fn2 = fn2[(fn2['epoch'] == 'ep1.TRC.txt')]  \n",
    "    y = pd.read_csv(labloc, sep=',',header=0)\n",
    "    yp = pd.DataFrame(y)\n",
    "    yp.columns= ['id','gender','age','diagnosis']\n",
    "    yp.id = pd.to_numeric(yp.id)\n",
    "    yp = yp[(yp['diagnosis'] < 3)] \n",
    "    ynew = merge(fn2,yp,left_on='id',right_on='id',how='inner')\n",
    "    filenames = ynew['filename'].values.tolist()\n",
    "    return(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = select_filenames(datadir=\"/media/windows-share/utrecht_eeg\",\n",
    "                            labloc = \"/home/vincent/estep/data/utrecht_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getdata(datadir,labloc,multivar,timecol,printfilenames,filenames,maxtslength=None):\n",
    "    Nfiles = len(filenames) # number of files\n",
    "    # Investigate what format the first file has by trying out a variety of reading attempts\n",
    "    path = datadir + '/' + filenames[0]\n",
    "    delimiter = [None,','] #possible delimiter values\n",
    "    skiprows=[0,1]\n",
    "    ntests = len(delimiter)*len(skiprows)\n",
    "    df = pd.DataFrame(index=range(ntests),columns=['delimiter','skiprows','nrow','ncol','first cell'])\n",
    "    cnt = 0\n",
    "    for di in delimiter:\n",
    "        for si in skiprows:\n",
    "            df['delimiter'][cnt] = di\n",
    "            df['skiprows'][cnt] = si\n",
    "            try:\n",
    "                F1 = np.loadtxt(fname=path,delimiter=di,skiprows=si)\n",
    "                df['nrow'][cnt] = F1.shape[0]\n",
    "                df['ncol'][cnt] = F1.shape[1]\n",
    "                df['first cell'][cnt] = F1[0,1]\n",
    "            except:\n",
    "                df['nrow'][cnt] = 0\n",
    "                df['ncol'][cnt] = 0\n",
    "                df['first cell'][cnt] = 0\n",
    "            cnt = cnt + 1\n",
    "    # df is now a dataframe with information to help identify how the data should be loaded\n",
    "    # load one file based on the extracted information on fileformat\n",
    "    form = df[df.nrow == max(df.nrow)] # extraction procedure that resulted in the largest number of rows is the best\n",
    "    if form.shape[0] > 1:\n",
    "        form = df[df.ncol == max(df.ncol)] # extraction procedure that resulted in the largest number of columns\n",
    "    if maxtslength != None:\n",
    "        X = np.zeros((Nfiles,maxtslength,form.ncol)) # hardcoded expected datadimensions\n",
    "    else:\n",
    "        if type(labloc) == int:\n",
    "            X = np.zeros((0,form.ncol,1)) # hardcoded expected datadimensions\n",
    "            if labloc == 0:\n",
    "                y = np.zeros((0,1))\n",
    "            else: \n",
    "                y = np.zeros((form.ncol,1))\n",
    "        else:\n",
    "            X = np.zeros((0,form.ncol,1))\n",
    "            y = np.zeros((form.ncol,1))\n",
    "    filenamelist = list()\n",
    "    jj = j_rowused = j_fileused = 0 # setting counters\n",
    "    while jj < Nfiles:\n",
    "        if printfilenames:\n",
    "            print(filenames[jj],end=' ')\n",
    "        path = datadir + '/' + filenames[jj]\n",
    "        if (form['delimiter'] == ',').bool():\n",
    "            F2 = np.loadtxt(fname=path,delimiter=',',skiprows=int(form['skiprows']))\n",
    "        else:\n",
    "            F2 = np.loadtxt(fname=path,delimiter=None,skiprows=int(form['skiprows']))\n",
    "        if maxtslength != None: # Modify F2 to meet expected dimantions:\n",
    "            if F2.shape[0] >= maxtslength:\n",
    "                F2 = F2[0:maxtslength,]\n",
    "            elif F2.shape[0] < maxtslength:\n",
    "                jj += 1\n",
    "                print(\" NOT ENOUGH DATA\")\n",
    "                continue # we are not interested in files with less than maxtslength values\n",
    "        ## Extract label (y)\n",
    "        labtype = 'int'\n",
    "        if jj == 0 and type(labloc) == str: #for Utrecht we only want to get the y once\n",
    "            y = pd.read_csv(labloc, sep=',',header=0)\n",
    "        elif type(labloc) == int: # For UCR we want to get all y\n",
    "            if labloc == 0:\n",
    "                tmpa = np.array(F2[:,0],dtype=labtype,ndmin=2).transpose()\n",
    "                y = np.vstack((y,tmpa))\n",
    "            elif labloc == 1:\n",
    "                y = np.vstack((y,np.array(F2[0,:], dtype=labtype).transpose()))\n",
    "        ## Extract data (X)\n",
    "        if type(labloc) == str:\n",
    "            if timecol == False:\n",
    "                X[j_fileused,:,:] = F2.transpose()\n",
    "            else:\n",
    "                X[j_fileused,:,:] = F2    \n",
    "        elif type(labloc) == int:\n",
    "            tmpp = np.reshape(F2,(F2.shape[0],F2.shape[1],1))\n",
    "            X = np.vstack((X,tmpp))\n",
    "            j_rowused += F2.shape[0]-1\n",
    "        ## Remember filenames\n",
    "        filenamelist.append(filenames[jj])\n",
    "        jj += 1\n",
    "        j_rowused += 1\n",
    "        j_fileused += 1\n",
    "    return(X, y, filenamelist, Nfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincent/estep/.venv/lib/python3.4/site-packages/ipykernel/__main__.py:30: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "if studyname == 'Utrecht':\n",
    "    X, y, filenamelist, Nfiles = getdata(datadir = \"/media/windows-share/utrecht_eeg\",\n",
    "                                     labloc = \"/home/vincent/estep/data/utrecht_labels.csv\",\n",
    "                                     multivar = True,\n",
    "                                     timecol=True,printfilenames=False,filenames=filenames,\n",
    "                                        maxtslength=4000)\n",
    "elif studyname == 'UCR':\n",
    "    datadir = \"/home/vincent/estep/data/UCR_TS_Archive_2015/50words\"\n",
    "    filenames = listdir(datadir) \n",
    "    X, y, filenamelist, Nfiles = getdata(datadir = datadir,\n",
    "                                     labloc = 0,\n",
    "                                     multivar = False,\n",
    "                                     timecol=False,printfilenames=False,filenames=filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272, 4000, 21) (451, 4) 272 272\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape, len(filenamelist), Nfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For Utrecht data we now need a conversion from y to a y that matches the X\n",
    "# merge y and filenamelist id, to get labels per file\n",
    "def filtery(y,filenamelist):\n",
    "    fn = pd.DataFrame(filenamelist,columns=['filename'])\n",
    "    fn = fn.filename.str.split('_',expand=True)\n",
    "    fn.columns= ['id','epoch']\n",
    "    fn.id = pd.to_numeric(fn.id)\n",
    "    fn = fn[fn['epoch'] == 'ep1.TRC.txt']\n",
    "    ypandas = pd.DataFrame(y)\n",
    "    ypandas.columns= ['id','gender','age','diagnosis']\n",
    "    ypandas.id = pd.to_numeric(ypandas.id)\n",
    "    ynew = merge(fn,ypandas,left_on='id',right_on='id',how='inner')\n",
    "    ybackup = ynew\n",
    "    y = ynew.as_matrix()\n",
    "    y = y[:,4] # we are only interest in the diagnosis in column 4\n",
    "    return(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if studyname == 'Utrecht':\n",
    "    y = filtery(y,filenamelist)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272, 4000, 21) (272,) 272 272\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape, len(filenamelist), Nfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtrain = X[0:150,:,:]\n",
    "ytrain = np.array(y[0:150,],dtype='int')\n",
    "Xtest = X[151:,:,:]\n",
    "ytest = np.array(y[151:,],dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4000, 21) (150,) 272\n",
      "(121, 4000, 21) (121,) 272\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape, ytrain.shape, Nfiles)\n",
    "print(Xtest.shape, ytest.shape, Nfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if studyname == 'Utrecht':\n",
    "    ytrain -= 1\n",
    "    ytest -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design and compile some architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# Now, lets try to train some models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Merge, Dense, Dropout, Activation, LSTM\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ytrain_original = ytrain\n",
    "ytest_original = ytest\n",
    "ytrain = to_categorical(ytrain) #np.squeeze(\n",
    "ytest = to_categorical(ytest) #np.squeeze("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timesteps = Xtrain.shape[1]\n",
    "if studyname == 'UCR':\n",
    "    data_dim = 1\n",
    "    nb_classes = 51\n",
    "else:\n",
    "    data_dim = 21\n",
    "    nb_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if studyname == 'UCR':\n",
    "    model = Sequential()\n",
    "    # Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "    idim = timesteps\n",
    "    model.add(Dense(64, input_dim=idim, init='uniform'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, init='uniform'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, init='uniform'))\n",
    "    model.add(Activation('softmax'))\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4000, 21)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's try out another model\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(32, return_sequences=True,\n",
    "               input_shape=(Xtrain.shape[1], Xtrain.shape[2])))  # returns a sequence of vectors of dimension 32\n",
    "model2.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model2.add(LSTM(32))  # return a single vector of dimension 32\n",
    "model2.add(Dense(nb_classes, activation='softmax'))\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_1 (LSTM)                    (None, 4000, 32)      6912        lstm_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 4000, 32)      8320        lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (None, 32)            8320        lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 2)             66          lstm_3[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 23618\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the architectures / models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit model and store history of the fitting process\n",
    "if studyname == 'UCR':\n",
    "    Xtrain_tmp  = Xtrain\n",
    "    Xtrain_tmp = np.reshape(Xtrain,(Xtrain.shape[0],Xtrain.shape[1]))\n",
    "    History = model.fit(Xtrain_tmp, ytrain,\n",
    "              nb_epoch=5,batch_size=20,validation_split=0.2)\n",
    "#else:\n",
    "#   History = model.fit(X_train, y_train,\n",
    "#            nb_epoch=5,batch_size=20,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 61s - loss: 0.6856 - acc: 0.5500 - val_loss: 0.6404 - val_acc: 0.6667\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 60s - loss: 0.5569 - acc: 0.8417 - val_loss: 0.6153 - val_acc: 0.6667\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 59s - loss: 0.4782 - acc: 0.8750 - val_loss: 0.5770 - val_acc: 0.7000\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 64s - loss: 0.4014 - acc: 0.8917 - val_loss: 0.5627 - val_acc: 0.7000\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 68s - loss: 0.3296 - acc: 0.9417 - val_loss: 0.5360 - val_acc: 0.8000\n"
     ]
    }
   ],
   "source": [
    "#Fit model and store history of the fitting process\n",
    "History2 = model2.fit(Xtrain, ytrain,batch_size=20,\n",
    "                      nb_epoch=5,verbose=True,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate models on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2: [0.72132241972221811, 0.61157024596348286]\n"
     ]
    }
   ],
   "source": [
    "score2 = model2.evaluate(Xtest, ytest, batch_size=20,verbose=False)\n",
    "print('Model 2: ' + str(score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 9s     \n",
      "121/121 [==============================] - 9s     \n"
     ]
    }
   ],
   "source": [
    "classes2 = model2.predict_classes(Xtest, batch_size=20)\n",
    "proba2 = model2.predict_proba(Xtest, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[62 33]\n",
      " [14 12]]\n",
      "kappa 0.0902255639098\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(classes2, ytest_original))\n",
    "print('kappa ' + str(metrics.cohen_kappa_score(classes2, ytest_original)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types dtype('<U32') dtype('<U32') dtype('<U32')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-e0afa9671f2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'auc '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytest_original\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreorder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types dtype('<U32') dtype('<U32') dtype('<U32')"
     ]
    }
   ],
   "source": [
    "metrics.auc(classes2, ytest_original,reorder=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(np.hstack((proba2, np.vstack((classes, ytest_original)).transpose())))\n",
    "#print(np.hstack((proba2, np.vstack((classes2, ytest_original)).transpose())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set up conditions for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot loss and accuracy for model 2\n",
    "#fig, ax1 = plt.subplots()\n",
    "#ax2 = ax1.twinx()\n",
    "#LN = len(History.history['val_loss'])\n",
    "#ax1.plot(range(LN),History.history['val_loss'],'g-')\n",
    "#ax2.plot(range(LN),History.history['val_acc'],'b-')\n",
    "#ax1.set_xlabel('epoch')\n",
    "#ax1.set_ylabel('loss',color='g')\n",
    "#ax2.set_ylabel('accuracy',color='b')\n",
    "#plt.title('Model 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot loss and accuracy for model 2\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "LN = len(History2.history['val_loss'])\n",
    "ax1.plot(range(LN),History2.history['val_loss'],'g-')\n",
    "ax2.plot(range(LN),History2.history['val_acc'],'b-')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('loss',color='g')\n",
    "ax2.set_ylabel('accuracy',color='b')\n",
    "plt.title('Model 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
