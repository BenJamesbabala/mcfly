{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment PAMAP2 with mcfly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This turorial is intended to talk you through the functionalities of mcfly. As an example dataset we use the publicly available PAMAP2 dataset. It contains time series data from movement sensors worn by nine individuals. The data is labelled with the activity types that these individuals did and the aim is to train and evaluate a classifier.\n",
    "\n",
    "Before you can start, please make sure you installed all the dependencies of mcfly (listed in requirements.txt) and make sure your jupyter notebook has a python3 kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# mcfly\n",
    "from mcfly import tutorial_pamap2, modelgen, find_architecture, storage\n",
    "# Keras module is use for the deep learning\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution1D, Flatten, MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "# We can set some backend options to avoid NaNs\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data and pre-proces data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a function for you to fetch and pre-proces the data. Please specify the 'directory_to_extract_to' in the code below and then execute the cell. This will download the data into the directory and create a subdirectory 'PAMAP2'. The second time you run this cell the function will recognize that you previously fetched and processed the data and it will skipp the processing. The output of the function is outputpath which indicates where the data was previously stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data previously downloaded and stored in /media/sf_VBox_Shared/timeseries//PAMAP2\n",
      "Data previously pre-processed and np-files saved to /media/sf_VBox_Shared/timeseries//PAMAP2/PAMAP2_Dataset/slidingwindow512cleaned/\n"
     ]
    }
   ],
   "source": [
    "# Specify in which directory you want to store the data:\n",
    "directory_to_extract_to = \"/media/sf_VBox_Shared/timeseries/\"\n",
    "# Specifcy which columns to use. You can leave this as it is \n",
    "columns_to_use = ['hand_acc_16g_x', 'hand_acc_16g_y', 'hand_acc_16g_z',\n",
    "                 'ankle_acc_16g_x', 'ankle_acc_16g_y', 'ankle_acc_16g_z',\n",
    "                 'chest_acc_16g_x', 'chest_acc_16g_y', 'chest_acc_16g_z']\n",
    "outputpath = tutorial_pamap2.fetch_and_preprocess(directory_to_extract_to,columns_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pre-processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the preprocessed data as stored in Numpy-files. Please note that the data has already been split up in a training (training), validation (val), and test subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12497, 512, 9)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train_binary, X_val, y_val_binary, X_test, y_test_binary = tutorial_pamap2.load_data(outputpath)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to create a model architecture. As we do not know what architecture is best for our data we will create a set of models to investigate which architecture is most suitable for our data and classification task. You will need to specificy how many models you want to create with argument 'number_of_models', the type of model which can been 'CNN' or 'DeepConvLSTM', and maximum number of layers per modeltype. See for a full overview of the optional arguments the function documentation of modelgen.generate_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_classes = y_train_binary.shape[1]\n",
    "np.random.seed(123)\n",
    "models = modelgen.generate_models(X_train.shape,\n",
    "                                  number_of_classes=num_classes,\n",
    "                                  number_of_models = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare models\n",
    "Now that the model architectures have been generated it is time to compare the models by training them in a subset of the training data and evaluating the models in the validation subset. This will help us to choose the best candidate model. Performance results are stored in a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define directory where the results, e.g. json file, will be stored\n",
    "resultpath = directory_to_extract_to + '/PAMAP2/PAMAP2_Dataset/results/' \n",
    "if not os.path.exists(resultpath):\n",
    "        os.makedirs(resultpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 264s - loss: 5.4757 - acc: 0.2360 - val_loss: 1.8126 - val_acc: 0.4056\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 253s - loss: 2.9033 - acc: 0.3260 - val_loss: 1.6804 - val_acc: 0.4056\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 255s - loss: 2.7290 - acc: 0.3340 - val_loss: 1.6941 - val_acc: 0.4175\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 304s - loss: 3.7647 - acc: 0.4260 - val_loss: 1.4799 - val_acc: 0.4150\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 257s - loss: 2.7018 - acc: 0.5000 - val_loss: 2.0925 - val_acc: 0.3607\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 266s - loss: 3.1476 - acc: 0.4420 - val_loss: 2.7559 - val_acc: 0.0583\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 255s - loss: 2.1628 - acc: 0.4980 - val_loss: 1.9769 - val_acc: 0.3009\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 258s - loss: 2.3782 - acc: 0.5320 - val_loss: 3.6892 - val_acc: 0.0488\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 265s - loss: 1.7789 - acc: 0.5620 - val_loss: 1.2209 - val_acc: 0.4674\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 265s - loss: 2.5996 - acc: 0.5320 - val_loss: 1.0633 - val_acc: 0.6074\n",
      "Training model 1 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 215s - loss: 3.2630 - acc: 0.1240 - val_loss: 2.3866 - val_acc: 0.1006\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 210s - loss: 2.7568 - acc: 0.1500 - val_loss: 2.3509 - val_acc: 0.1345\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 206s - loss: 2.5551 - acc: 0.1480 - val_loss: 2.3687 - val_acc: 0.1345\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 197s - loss: 2.4595 - acc: 0.1340 - val_loss: 2.3504 - val_acc: 0.1345\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 195s - loss: 2.4150 - acc: 0.1480 - val_loss: 2.3536 - val_acc: 0.1345\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 195s - loss: 2.3953 - acc: 0.1380 - val_loss: 2.3395 - val_acc: 0.1345\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 194s - loss: 2.3989 - acc: 0.1420 - val_loss: 2.3675 - val_acc: 0.1345\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 196s - loss: 2.3954 - acc: 0.1420 - val_loss: 2.3431 - val_acc: 0.1345\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 200s - loss: 2.3837 - acc: 0.1420 - val_loss: 2.3623 - val_acc: 0.1345\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 197s - loss: 2.3980 - acc: 0.1400 - val_loss: 2.3398 - val_acc: 0.1560\n",
      "Training model 2 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 205s - loss: 2.6941 - acc: 0.1800 - val_loss: 2.2133 - val_acc: 0.3468\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 225s - loss: 2.4798 - acc: 0.2720 - val_loss: 2.5202 - val_acc: 0.2975\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 217s - loss: 2.4878 - acc: 0.2340 - val_loss: 2.0631 - val_acc: 0.3004\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 218s - loss: 2.3585 - acc: 0.2640 - val_loss: 1.6715 - val_acc: 0.3747\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 222s - loss: 2.1982 - acc: 0.2740 - val_loss: 1.8298 - val_acc: 0.3657\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 184s - loss: 2.1736 - acc: 0.2520 - val_loss: 2.3397 - val_acc: 0.3403\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 187s - loss: 2.2560 - acc: 0.2460 - val_loss: 1.4840 - val_acc: 0.4410\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 188s - loss: 2.0582 - acc: 0.2820 - val_loss: 1.6114 - val_acc: 0.3328\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 221s - loss: 1.9742 - acc: 0.2820 - val_loss: 1.7419 - val_acc: 0.2387\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 241s - loss: 2.0450 - acc: 0.2600 - val_loss: 1.4266 - val_acc: 0.4215\n",
      "Training model 3 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 40s - loss: 3.8232 - acc: 0.4520 - val_loss: 1.5998 - val_acc: 0.6079\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 37s - loss: 3.3814 - acc: 0.7460 - val_loss: 0.8361 - val_acc: 0.8296\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 40s - loss: 2.7987 - acc: 0.7980 - val_loss: 0.7829 - val_acc: 0.8500\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 39s - loss: 2.4219 - acc: 0.8160 - val_loss: 0.5507 - val_acc: 0.8675\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 37s - loss: 2.1166 - acc: 0.8780 - val_loss: 0.7929 - val_acc: 0.8271\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 43s - loss: 1.8743 - acc: 0.8940 - val_loss: 0.8460 - val_acc: 0.7529\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 37s - loss: 1.7295 - acc: 0.9000 - val_loss: 0.5971 - val_acc: 0.8809\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 37s - loss: 1.7153 - acc: 0.8820 - val_loss: 0.7879 - val_acc: 0.8430\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 37s - loss: 1.6220 - acc: 0.8900 - val_loss: 0.7036 - val_acc: 0.8366\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 37s - loss: 1.5159 - acc: 0.9160 - val_loss: 0.6276 - val_acc: 0.8520\n",
      "Training model 4 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 30s - loss: 2.4105 - acc: 0.4340 - val_loss: 1.3869 - val_acc: 0.6487\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 31s - loss: 1.6814 - acc: 0.7760 - val_loss: 1.0666 - val_acc: 0.7534\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 33s - loss: 1.4878 - acc: 0.8520 - val_loss: 0.9739 - val_acc: 0.7798\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 38s - loss: 1.3357 - acc: 0.9200 - val_loss: 1.0017 - val_acc: 0.7798\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 39s - loss: 1.2243 - acc: 0.9400 - val_loss: 1.0131 - val_acc: 0.7857\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 34s - loss: 1.1845 - acc: 0.9480 - val_loss: 1.0485 - val_acc: 0.7384\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 32s - loss: 1.1730 - acc: 0.9480 - val_loss: 1.0060 - val_acc: 0.7678\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 34s - loss: 1.1899 - acc: 0.9520 - val_loss: 0.9580 - val_acc: 0.7798\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 37s - loss: 1.1298 - acc: 0.9580 - val_loss: 0.9987 - val_acc: 0.7638\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 31s - loss: 1.1300 - acc: 0.9620 - val_loss: 0.9857 - val_acc: 0.7803\n",
      "Training model 5 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 56s - loss: 45.8359 - acc: 0.4200 - val_loss: 1.7010 - val_acc: 0.3866\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 63s - loss: 26.8179 - acc: 0.6440 - val_loss: 1.8749 - val_acc: 0.3787\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 61s - loss: 10.2237 - acc: 0.6680 - val_loss: 1.6575 - val_acc: 0.3911\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 66s - loss: 5.6751 - acc: 0.6220 - val_loss: 1.0674 - val_acc: 0.6866\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 74s - loss: 4.2345 - acc: 0.6280 - val_loss: 1.5649 - val_acc: 0.5117\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 66s - loss: 3.3261 - acc: 0.6860 - val_loss: 1.7970 - val_acc: 0.3991\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 63s - loss: 3.0364 - acc: 0.6240 - val_loss: 1.9051 - val_acc: 0.5705\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 58s - loss: 2.9418 - acc: 0.6060 - val_loss: 2.3979 - val_acc: 0.5690\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 59s - loss: 2.7852 - acc: 0.6360 - val_loss: 1.6595 - val_acc: 0.5740\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 60s - loss: 2.5834 - acc: 0.6440 - val_loss: 3.1810 - val_acc: 0.4310\n",
      "Training model 6 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 251s - loss: 12.0243 - acc: 0.1240 - val_loss: 2.3680 - val_acc: 0.1345\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 241s - loss: 4.5658 - acc: 0.1660 - val_loss: 2.3858 - val_acc: 0.1345\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 285s - loss: 3.4981 - acc: 0.1260 - val_loss: 2.3532 - val_acc: 0.1345\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 251s - loss: 2.8807 - acc: 0.1300 - val_loss: 2.3584 - val_acc: 0.1345\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 217s - loss: 2.6531 - acc: 0.1460 - val_loss: 2.3612 - val_acc: 0.1345\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 242s - loss: 2.5231 - acc: 0.1140 - val_loss: 2.3660 - val_acc: 0.1345\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 231s - loss: 2.4663 - acc: 0.1320 - val_loss: 2.3657 - val_acc: 0.1345\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 222s - loss: 2.4246 - acc: 0.1400 - val_loss: 2.3744 - val_acc: 0.1345\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 221s - loss: 2.4150 - acc: 0.1440 - val_loss: 2.3544 - val_acc: 0.1345\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 244s - loss: 2.4118 - acc: 0.1200 - val_loss: 2.3523 - val_acc: 0.1560\n",
      "Training model 7 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 580s - loss: nan - acc: 0.1300 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 355s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 363s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 385s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 358s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 360s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 413s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 420s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 415s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 419s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Training model 8 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 29s - loss: 65.5579 - acc: 0.5600 - val_loss: 2.1297 - val_acc: 0.1749\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 29s - loss: 9.4563 - acc: 0.6700 - val_loss: 1.2942 - val_acc: 0.5795\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 31s - loss: 4.0441 - acc: 0.7120 - val_loss: 1.1762 - val_acc: 0.6363\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 33s - loss: 3.8447 - acc: 0.6860 - val_loss: 1.2447 - val_acc: 0.6502\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 31s - loss: 3.9758 - acc: 0.7060 - val_loss: 0.9916 - val_acc: 0.7000\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 30s - loss: 3.5002 - acc: 0.7200 - val_loss: 1.0058 - val_acc: 0.6876\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 29s - loss: 3.6563 - acc: 0.7160 - val_loss: 1.2626 - val_acc: 0.5371\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 29s - loss: 3.5769 - acc: 0.7300 - val_loss: 1.0202 - val_acc: 0.6423\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 29s - loss: 3.4662 - acc: 0.7040 - val_loss: 0.8010 - val_acc: 0.7439\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 29s - loss: 3.8556 - acc: 0.7300 - val_loss: 0.9766 - val_acc: 0.6303\n",
      "Training model 9 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 415s - loss: 17.1257 - acc: 0.2340 - val_loss: 2.1687 - val_acc: 0.4031\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 444s - loss: 16.2093 - acc: 0.4020 - val_loss: 1.9268 - val_acc: 0.4459\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 3037s - loss: 15.4312 - acc: 0.4340 - val_loss: 1.7760 - val_acc: 0.4798\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 335s - loss: 14.7004 - acc: 0.4700 - val_loss: 1.6667 - val_acc: 0.5396\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 347s - loss: 13.9788 - acc: 0.5240 - val_loss: 1.5341 - val_acc: 0.5381\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 358s - loss: 13.3355 - acc: 0.5400 - val_loss: 1.4547 - val_acc: 0.6363\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 359s - loss: 12.7603 - acc: 0.5660 - val_loss: 1.3574 - val_acc: 0.6876\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 135749s - loss: 12.1716 - acc: 0.6260 - val_loss: 1.2579 - val_acc: 0.7339\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 409s - loss: 11.6515 - acc: 0.6540 - val_loss: 1.2225 - val_acc: 0.7110\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 384s - loss: 11.1354 - acc: 0.7020 - val_loss: 1.0855 - val_acc: 0.7997\n",
      "Training model 10 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 534s - loss: 7.4479 - acc: 0.1620 - val_loss: 2.0270 - val_acc: 0.4718\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 408s - loss: 6.2308 - acc: 0.4240 - val_loss: 1.7172 - val_acc: 0.5800\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 536s - loss: 5.2220 - acc: 0.5780 - val_loss: 1.3732 - val_acc: 0.7434\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1126s - loss: 4.4715 - acc: 0.6160 - val_loss: 1.1751 - val_acc: 0.7185\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 541s - loss: 3.7710 - acc: 0.7180 - val_loss: 0.9976 - val_acc: 0.7987\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 465s - loss: 3.2456 - acc: 0.7540 - val_loss: 0.8808 - val_acc: 0.7942\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 508s - loss: 2.9573 - acc: 0.7340 - val_loss: 0.8455 - val_acc: 0.7748\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 456s - loss: 2.6618 - acc: 0.7500 - val_loss: 0.7690 - val_acc: 0.8251\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 486s - loss: 2.4411 - acc: 0.7880 - val_loss: 0.7778 - val_acc: 0.8236\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 468s - loss: 2.2958 - acc: 0.7780 - val_loss: 0.7876 - val_acc: 0.7733\n",
      "Training model 11 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 14s - loss: 2.8688 - acc: 0.5980 - val_loss: 1.0018 - val_acc: 0.7205\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 15s - loss: 3.1055 - acc: 0.8180 - val_loss: 0.8314 - val_acc: 0.7598\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 15s - loss: 2.7676 - acc: 0.8500 - val_loss: 0.7051 - val_acc: 0.8645\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 14s - loss: 2.4058 - acc: 0.8700 - val_loss: 0.6680 - val_acc: 0.8719\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 15s - loss: 2.1007 - acc: 0.8760 - val_loss: 0.6498 - val_acc: 0.8161\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 15s - loss: 1.7445 - acc: 0.9360 - val_loss: 0.5231 - val_acc: 0.8769\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 15s - loss: 1.5514 - acc: 0.9480 - val_loss: 0.5572 - val_acc: 0.8690\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 14s - loss: 1.4566 - acc: 0.9200 - val_loss: 0.6413 - val_acc: 0.8012\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 14s - loss: 1.3054 - acc: 0.9360 - val_loss: 0.6198 - val_acc: 0.8052\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 14s - loss: 1.2272 - acc: 0.9200 - val_loss: 0.5590 - val_acc: 0.8475\n",
      "Training model 12 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 54s - loss: 448.4724 - acc: 0.2780 - val_loss: 2.1776 - val_acc: 0.3981\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 53s - loss: 38.7044 - acc: 0.3180 - val_loss: 2.1942 - val_acc: 0.2581\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 54s - loss: 17.4477 - acc: 0.2880 - val_loss: 2.4626 - val_acc: 0.1345\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 60s - loss: 9.3126 - acc: 0.3460 - val_loss: 2.4128 - val_acc: 0.1345\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 60s - loss: 9.3698 - acc: 0.3560 - val_loss: 2.0391 - val_acc: 0.2083\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 60s - loss: 10.4977 - acc: 0.3360 - val_loss: 2.6773 - val_acc: 0.1345\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 60s - loss: 9.1226 - acc: 0.3280 - val_loss: 2.9139 - val_acc: 0.1560\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 60s - loss: 9.6260 - acc: 0.3320 - val_loss: 1.9001 - val_acc: 0.2496\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 59s - loss: 11.4104 - acc: 0.3400 - val_loss: 2.3574 - val_acc: 0.1734\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 59s - loss: 10.2112 - acc: 0.3080 - val_loss: 3.1187 - val_acc: 0.1151\n",
      "Training model 13 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 29s - loss: 220.4660 - acc: 0.2080 - val_loss: 2.5154 - val_acc: 0.1355\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 30s - loss: 21.5434 - acc: 0.2500 - val_loss: 2.5579 - val_acc: 0.1345\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 38s - loss: 7.3049 - acc: 0.3220 - val_loss: 2.9330 - val_acc: 0.1345\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 32s - loss: 6.3343 - acc: 0.2920 - val_loss: 2.6060 - val_acc: 0.1560\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 29s - loss: 5.6812 - acc: 0.2960 - val_loss: 2.5228 - val_acc: 0.1345\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 29s - loss: 5.5297 - acc: 0.3220 - val_loss: 14.7285 - val_acc: 0.0060\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 29s - loss: 5.4938 - acc: 0.3720 - val_loss: 2.2171 - val_acc: 0.1988\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 29s - loss: 4.3335 - acc: 0.3460 - val_loss: 10.3634 - val_acc: 0.1151\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 29s - loss: 5.9388 - acc: 0.3680 - val_loss: 3.6002 - val_acc: 0.1345\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 29s - loss: 6.9201 - acc: 0.3440 - val_loss: 2.2306 - val_acc: 0.2905\n",
      "Training model 14 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 31s - loss: 2.1219 - acc: 0.4760 - val_loss: 1.6700 - val_acc: 0.5107\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 31s - loss: 1.6357 - acc: 0.6940 - val_loss: 0.8203 - val_acc: 0.7698\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 29s - loss: 1.3264 - acc: 0.7840 - val_loss: 0.8948 - val_acc: 0.7544\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 29s - loss: 1.2689 - acc: 0.8160 - val_loss: 0.8587 - val_acc: 0.8052\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 30s - loss: 1.1519 - acc: 0.8220 - val_loss: 0.8313 - val_acc: 0.8336\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 30s - loss: 1.0081 - acc: 0.8640 - val_loss: 0.7664 - val_acc: 0.7723\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 29s - loss: 0.9529 - acc: 0.8520 - val_loss: 0.7608 - val_acc: 0.8012\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 30s - loss: 0.8860 - acc: 0.9000 - val_loss: 0.8481 - val_acc: 0.7738\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 30s - loss: 0.8123 - acc: 0.8880 - val_loss: 0.6417 - val_acc: 0.8540\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 30s - loss: 0.8584 - acc: 0.8900 - val_loss: 0.6183 - val_acc: 0.8625\n",
      "Training model 15 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 24s - loss: 22.5016 - acc: 0.5360 - val_loss: 1.2584 - val_acc: 0.6313\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 24s - loss: 18.1711 - acc: 0.7660 - val_loss: 1.2033 - val_acc: 0.7828\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 24s - loss: 14.1875 - acc: 0.8420 - val_loss: 1.1299 - val_acc: 0.7838\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 24s - loss: 11.0386 - acc: 0.9020 - val_loss: 1.2437 - val_acc: 0.7793\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 24s - loss: 8.7088 - acc: 0.8900 - val_loss: 1.1157 - val_acc: 0.7853\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 24s - loss: 6.9807 - acc: 0.9120 - val_loss: 1.1901 - val_acc: 0.7703\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 24s - loss: 5.6851 - acc: 0.9200 - val_loss: 1.2711 - val_acc: 0.7265\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 24s - loss: 4.7663 - acc: 0.9220 - val_loss: 1.1099 - val_acc: 0.7972\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 24s - loss: 4.0548 - acc: 0.9240 - val_loss: 1.1195 - val_acc: 0.7618\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 24s - loss: 3.5922 - acc: 0.9040 - val_loss: 1.1285 - val_acc: 0.7853\n",
      "Training model 16 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 283s - loss: 5.1601 - acc: 0.1220 - val_loss: 2.3220 - val_acc: 0.2845\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 283s - loss: 3.8871 - acc: 0.2000 - val_loss: 2.2266 - val_acc: 0.2496\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 291s - loss: 3.2346 - acc: 0.2580 - val_loss: 1.7876 - val_acc: 0.3747\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 290s - loss: 2.7455 - acc: 0.3540 - val_loss: 1.6126 - val_acc: 0.4021\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 288s - loss: 2.4155 - acc: 0.4080 - val_loss: 1.4812 - val_acc: 0.4439\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 289s - loss: 2.2479 - acc: 0.4400 - val_loss: 1.2665 - val_acc: 0.5590\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 317s - loss: 2.0704 - acc: 0.5140 - val_loss: 1.2907 - val_acc: 0.5929\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 296s - loss: 2.0673 - acc: 0.4480 - val_loss: 1.4686 - val_acc: 0.6263\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 420s - loss: 1.8570 - acc: 0.5200 - val_loss: 1.2377 - val_acc: 0.6916\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 732s - loss: 1.5882 - acc: 0.5900 - val_loss: 0.9346 - val_acc: 0.7185\n",
      "Training model 17 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 88s - loss: 5.8782 - acc: 0.6340 - val_loss: 1.0966 - val_acc: 0.6781\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 89s - loss: 7.3977 - acc: 0.7280 - val_loss: 1.0488 - val_acc: 0.6756\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 105s - loss: 5.9324 - acc: 0.7620 - val_loss: 0.8719 - val_acc: 0.8490\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 94s - loss: 4.6199 - acc: 0.8320 - val_loss: 0.9350 - val_acc: 0.7693\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 87s - loss: 3.8005 - acc: 0.8220 - val_loss: 0.8604 - val_acc: 0.7065\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 86s - loss: 3.0795 - acc: 0.8520 - val_loss: 0.8192 - val_acc: 0.7598\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 86s - loss: 2.5568 - acc: 0.8680 - val_loss: 0.7295 - val_acc: 0.8206\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 84s - loss: 2.1212 - acc: 0.9200 - val_loss: 0.8224 - val_acc: 0.7210\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 95s - loss: 1.8707 - acc: 0.9040 - val_loss: 0.5099 - val_acc: 0.8710\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 84s - loss: 1.6601 - acc: 0.9120 - val_loss: 0.8000 - val_acc: 0.7314\n",
      "Training model 18 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 681s - loss: 2.6489 - acc: 0.1620 - val_loss: 2.3026 - val_acc: 0.3896\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 623s - loss: 2.5414 - acc: 0.2560 - val_loss: 2.1367 - val_acc: 0.5132\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 653s - loss: 2.4118 - acc: 0.3420 - val_loss: 2.0729 - val_acc: 0.5526\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 707s - loss: 2.3150 - acc: 0.4160 - val_loss: 2.0327 - val_acc: 0.5162\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 678s - loss: 2.2600 - acc: 0.4020 - val_loss: 1.9163 - val_acc: 0.6188\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 778s - loss: 2.2006 - acc: 0.4660 - val_loss: 1.8634 - val_acc: 0.6776\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 774s - loss: 2.1288 - acc: 0.4760 - val_loss: 1.8659 - val_acc: 0.6069\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 408s - loss: 2.1251 - acc: 0.5000 - val_loss: 1.7883 - val_acc: 0.7020\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 345s - loss: 2.0698 - acc: 0.5480 - val_loss: 1.7166 - val_acc: 0.6916\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 328s - loss: 1.9586 - acc: 0.5620 - val_loss: 1.6986 - val_acc: 0.6841\n",
      "Training model 19 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 262s - loss: 2.4219 - acc: 0.1780 - val_loss: 1.9794 - val_acc: 0.4096\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 242s - loss: 1.9747 - acc: 0.3920 - val_loss: 1.5222 - val_acc: 0.4773\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 244s - loss: 1.6412 - acc: 0.4880 - val_loss: 1.5028 - val_acc: 0.5356\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 296s - loss: 1.4910 - acc: 0.5820 - val_loss: 1.1081 - val_acc: 0.7374\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 268s - loss: 1.3055 - acc: 0.6300 - val_loss: 0.8814 - val_acc: 0.7997\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 266s - loss: 1.2218 - acc: 0.6460 - val_loss: 0.7413 - val_acc: 0.7902\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 267s - loss: 1.1130 - acc: 0.6800 - val_loss: 0.7306 - val_acc: 0.8047\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 267s - loss: 1.1434 - acc: 0.6700 - val_loss: 0.7948 - val_acc: 0.7578\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 267s - loss: 0.9816 - acc: 0.7180 - val_loss: 0.6148 - val_acc: 0.8201\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 273s - loss: 0.9183 - acc: 0.7480 - val_loss: 0.4787 - val_acc: 0.8814\n",
      "Training model 20 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 143s - loss: 3.0790 - acc: 0.1960 - val_loss: 2.0084 - val_acc: 0.2835\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 155s - loss: 2.0352 - acc: 0.3800 - val_loss: 2.5040 - val_acc: 0.1799\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 152s - loss: 2.5942 - acc: 0.2500 - val_loss: 1.7871 - val_acc: 0.4205\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 130s - loss: nan - acc: 0.3220 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 118s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 109s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 113s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 130s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 117s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 119s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Training model 21 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 168s - loss: 2.6467 - acc: 0.2980 - val_loss: 1.8913 - val_acc: 0.6303\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 171s - loss: 2.2255 - acc: 0.5340 - val_loss: 1.5588 - val_acc: 0.7887\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 173s - loss: 1.9737 - acc: 0.6260 - val_loss: 1.3359 - val_acc: 0.8201\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 170s - loss: 1.7975 - acc: 0.6500 - val_loss: 1.1912 - val_acc: 0.8052\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 175s - loss: 1.6400 - acc: 0.7080 - val_loss: 0.9977 - val_acc: 0.8705\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 172s - loss: 1.5035 - acc: 0.7200 - val_loss: 0.8876 - val_acc: 0.8565\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 173s - loss: 1.4317 - acc: 0.7580 - val_loss: 0.9215 - val_acc: 0.8082\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 175s - loss: 1.3740 - acc: 0.7700 - val_loss: 0.8274 - val_acc: 0.8590\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 172s - loss: 1.3625 - acc: 0.7560 - val_loss: 0.8034 - val_acc: 0.8500\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 168s - loss: 1.2172 - acc: 0.7980 - val_loss: 0.7272 - val_acc: 0.8406\n",
      "Training model 22 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 44s - loss: 2052.9905 - acc: 0.1520 - val_loss: 2.3473 - val_acc: 0.3209\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 45s - loss: 148.2609 - acc: 0.3000 - val_loss: 10.2992 - val_acc: 0.1151\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 45s - loss: 22.2990 - acc: 0.2600 - val_loss: 4.6406 - val_acc: 0.1151\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 44s - loss: 17.0808 - acc: 0.2740 - val_loss: 2.7048 - val_acc: 0.0060\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 45s - loss: 13.6464 - acc: 0.2940 - val_loss: 7.4735 - val_acc: 0.1151\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 45s - loss: 13.6135 - acc: 0.2560 - val_loss: 14.1535 - val_acc: 0.0060\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 45s - loss: 15.9514 - acc: 0.2720 - val_loss: 10.8188 - val_acc: 0.0060\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 44s - loss: 15.1384 - acc: 0.2900 - val_loss: 8.1994 - val_acc: 0.1211\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 51s - loss: 39.5710 - acc: 0.2680 - val_loss: 12.2525 - val_acc: 0.0060\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 47s - loss: 25.2268 - acc: 0.3280 - val_loss: 2.2126 - val_acc: 0.2262\n",
      "Training model 23 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 44s - loss: 1.7400 - acc: 0.5540 - val_loss: 1.0824 - val_acc: 0.8102\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 40s - loss: 1.1292 - acc: 0.8140 - val_loss: 0.9199 - val_acc: 0.8027\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 42s - loss: 0.9626 - acc: 0.8620 - val_loss: 0.8209 - val_acc: 0.8570\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 43s - loss: 0.8433 - acc: 0.9320 - val_loss: 0.8998 - val_acc: 0.8221\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 40s - loss: 0.8737 - acc: 0.8920 - val_loss: 0.9042 - val_acc: 0.8535\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 40s - loss: 0.7763 - acc: 0.9360 - val_loss: 0.8962 - val_acc: 0.8575\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 40s - loss: 0.7390 - acc: 0.9500 - val_loss: 1.0260 - val_acc: 0.8037\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 38s - loss: 0.7322 - acc: 0.9500 - val_loss: 0.9730 - val_acc: 0.8326\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 39s - loss: 0.6659 - acc: 0.9680 - val_loss: 0.9909 - val_acc: 0.7912\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 39s - loss: 0.6721 - acc: 0.9620 - val_loss: 0.9288 - val_acc: 0.8186\n",
      "Training model 24 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 61s - loss: 5.3517 - acc: 0.6100 - val_loss: 1.0449 - val_acc: 0.6682\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 61s - loss: 4.9238 - acc: 0.8240 - val_loss: 0.8116 - val_acc: 0.8132\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 57s - loss: 3.7838 - acc: 0.8680 - val_loss: 0.9065 - val_acc: 0.7270\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 62s - loss: 2.9822 - acc: 0.9140 - val_loss: 0.5879 - val_acc: 0.9178\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 66s - loss: 2.4320 - acc: 0.9300 - val_loss: 0.6623 - val_acc: 0.9018\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 55s - loss: 2.1749 - acc: 0.9100 - val_loss: 0.6407 - val_acc: 0.8371\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 55s - loss: 1.9658 - acc: 0.8960 - val_loss: 0.5754 - val_acc: 0.8894\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 57s - loss: 1.7006 - acc: 0.9420 - val_loss: 0.6265 - val_acc: 0.9008\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 58s - loss: 1.5262 - acc: 0.9260 - val_loss: 0.6098 - val_acc: 0.8919\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 55s - loss: 1.4297 - acc: 0.9420 - val_loss: 0.5814 - val_acc: 0.9038\n",
      "182695.70508646965\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "histories, val_accuracies, val_losses = find_architecture.train_models_on_samples(X_train, y_train_binary,\n",
    "                                                                           X_val, y_val_binary,\n",
    "                                                                           models,nr_epochs=10,\n",
    "                                                                           subset_size=500,\n",
    "                                                                           verbose=True,\n",
    "                                                                           outputfile=resultpath+\\\n",
    "                                                                                  'experiment.json')\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histories object produced by the previous step contains the history of classifier performance with every iteration of the training process. To ease inspecting this information we developed function plotTrainingProcess, which is demonstrated in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of comparing model performance is by putting all the information in a pandas dataframe, which we can store in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'filters': array([94]), 'learning_rate': 0.05...</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>11.924376</td>\n",
       "      <td>0.512207</td>\n",
       "      <td>1.655583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'filters': array([79, 64, 90]), 'learning_rat...</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>6.713034</td>\n",
       "      <td>0.835575</td>\n",
       "      <td>1.017291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  train_acc  train_loss  \\\n",
       "0  {'filters': array([94]), 'learning_rate': 0.05...   0.706667   11.924376   \n",
       "1  {'filters': array([79, 64, 90]), 'learning_rat...   0.923333    6.713034   \n",
       "\n",
       "    val_acc  val_loss  \n",
       "0  0.512207  1.655583  \n",
       "1  0.835575  1.017291  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelcomparisons = pd.DataFrame({'model':[str(params) for model, params, model_types in models],\n",
    "                       'train_acc': [history.history['acc'][-1] for history in histories],\n",
    "                       'train_loss': [history.history['loss'][-1] for history in histories],\n",
    "                       'val_acc': [history.history['val_acc'][-1] for history in histories],\n",
    "                       'val_loss': [history.history['val_loss'][-1] for history in histories]\n",
    "                       })\n",
    "modelcomparisons.to_csv(resultpath +'modelcomparisons.csv')\n",
    "\n",
    "modelcomparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to vizualize the performance of the various models using our vizualisation tool as explained in the mcfly repository README file: https://github.com/NLeSC/mcfly/blob/master/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Check which model is the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type and parameters of the best model:\n",
      "CNN\n",
      "{'regularization_rate': 0.0016693552595679474, 'learning_rate': 0.0013927354361231595, 'filters': array([ 69,  71,  90, 100,  29,  41]), 'fc_hidden_nodes': 1314}\n"
     ]
    }
   ],
   "source": [
    "best_model_index = np.argmax(val_accuracies)\n",
    "best_model, best_params, best_model_types = models[best_model_index]\n",
    "print('Model type and parameters of the best model:')\n",
    "print(best_model_types)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/media/sf_VBox_Shared/timeseries//PAMAP2/PAMAP2_Dataset/results/bestmodel_sample_architecture.json',\n",
       " '/media/sf_VBox_Shared/timeseries//PAMAP2/PAMAP2_Dataset/results/bestmodel_sample_weights')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelname = 'bestmodel_sample'\n",
    "storage.savemodel(best_model,resultpath,modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the best model for real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have identified the best model architecture out of our random pool of models we can continue by training the model on the full training sample. For the purpose of speeding up the example we only train the full model on the first 1000 values. You will need to replace this by 'datasize = X_train.shape[0]' in a real world example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12497 samples, validate on 2007 samples\n",
      "Epoch 1/1\n",
      "12497/12497 [==============================] - 592s - loss: 2.0438 - acc: 0.9119 - val_loss: 0.2887 - val_acc: 0.9841\n"
     ]
    }
   ],
   "source": [
    "#We make a copy of the model, to start training from fresh\n",
    "best_model_copy = modelgen.generate_CNN_model(X_train.shape, num_classes, best_params['filters'], best_params['fc_hidden_nodes'],\n",
    "                       best_params['learning_rate'], best_params['regularization_rate'])\n",
    "nr_epochs = 1\n",
    "datasize = X_train.shape[0] #We're going to train the model on the complete data set\n",
    "#datasize = 1000 # subsample for the sake of this example\n",
    "history = best_model_copy.fit(X_train[:datasize,:,:], y_train_binary[:datasize,:],\n",
    "              nb_epoch=nr_epochs, validation_data=(X_val, y_val_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the training process:\n",
    "find_architecture.plotTrainingProcess(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model_fullytrained = best_model_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of best model: [0.28872849385374272, 0.98405580468360743]\n"
     ]
    }
   ],
   "source": [
    "score_val = best_model_fullytrained.evaluate(X_val, y_val_binary, verbose=False)\n",
    "print('Score of best model: ' + str(score_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving, loading and comparing reloaded model with orignal model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modoel can be saved for future use. The savemodel function will save two separate files: a json file for the architecture and a npy (numpy array) file for the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelname = 'my_bestmodel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/media/sf_VBox_Shared/timeseries//PAMAP2/PAMAP2_Dataset/results/my_bestmodel_architecture.json',\n",
       " '/media/sf_VBox_Shared/timeseries//PAMAP2/PAMAP2_Dataset/results/my_bestmodel_weights')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage.savemodel(best_model_fullytrained,resultpath,modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_model_fullytrained = storage.loadmodel(resultpath,modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model_sample = storage.loadmodel(resultpath, 'bestmodel_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0013927354361231595\n",
    "best_model_fullytrained.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(lr=learning_rate),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model_sample.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(lr=learning_rate),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has been reloaded. Let's investigate whether it gives the same probability estimates as the original model in a small subset of the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced model inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although beyond the scope of mcfly it may be worth highlighting that the objects 'models', 'best_model_fullytrained' and 'best_model' are Keras objects. This means that you can use Keras functions like .predict and .evaluate on the objects to run advanced analyses. These functions are all documented in the Keras documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of best model: [1.5646683828375569, 0.52981849611063092]\n"
     ]
    }
   ],
   "source": [
    "## Test on Testset\n",
    "score_test = best_model_fullytrained.evaluate(X_test, y_test_binary, verbose=False)\n",
    "print('Score of best model: ' + str(score_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2314, 512, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.9208478596103324, 0.46672428694900603]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_sample.evaluate(X_test, y_test_binary, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007/2007 [==============================] - 40s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28872849385374272, 0.98405580468360743]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_fullytrained.evaluate(X_val, y_val_binary, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3595505617977528"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_architecture.kNN_accuracy(X_train[:500,:,:], y_train_binary[:500,], X_test, y_test_binary, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44294967613353264"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_architecture.kNN_accuracy(X_train[:500,:,:], y_train_binary[:500,], X_val, y_val_binary, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.359982713915\n",
      "0.470852017937\n"
     ]
    }
   ],
   "source": [
    "print(find_architecture.kNN_accuracy(X_train[:1000,:,:], y_train_binary[:1000,], X_test, y_test_binary, k=1))\n",
    "print(find_architecture.kNN_accuracy(X_train[:1000,:,:], y_train_binary[:1000,], X_val, y_val_binary, k=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
